{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6jO_1gISKxk"
      },
      "source": [
        "# Introducci√≥n a las neuronas artificiales üß†\n",
        "\n",
        "1. Brief hist√≥rico\n",
        "2. Unidad Umbralizaci√≥n Lineal (TLU)\n",
        "3. Activaci√≥n y bias ‚Äì El perceptr√≥n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPk1Rkc4FZ5g"
      },
      "source": [
        "### **Historia de las redes neuronales**\n",
        "\n",
        "Podr√≠amos decir que la historia se remonta a dar un inicio con el modelo neuronal de McCulloch y Pitts de 1943, la **Threshold Logic Unit (TLU)**, o **Linear Threshold Unit**,‚Äã que fue el primer modelo neuronal moderno, y ha servido de inspiraci√≥n para el desarrollo de otros modelos neuronales. (Puedes leer m√°s [aqu√≠](https://es.wikipedia.org/wiki/Neurona_de_McCulloch-Pitts).)\n",
        "\n",
        "Posterior a los TLU, se la historia se complementa con el desarrollo de un tipo de neurona artificial con una **funci√≥n de activaci√≥n**, llamada **perceptr√≥n**. √âsta fue desarrollada entre 1950 y 1960 por el cient√≠fico **Frank Rosenblatt**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uehq48zoSocy"
      },
      "source": [
        "### **Entonces, ¬øqu√© es una neurona artificial?**\n",
        "\n",
        "Una neurona artificial es una funci√≥n matem√°tica que concevida como un modelo de neuronas biol√≥gicas. (Puedes leer un poco m√°s [aqu√≠](https://en.wikipedia.org/wiki/Artificial_neuron).)\n",
        "\n",
        "El modelo general de una **neurona artificial** toma varias **entradas** $x_1, x_2,..., x_n $ y produce una **salida**. Se propuso que las entradas tuviesen **pesos** asciados $w_1, w_2, ..., w_n$, siendo √©stos n√∫meros reales que podemos interpretar como una expressi√≥n de la importancia respectiva para cada entrada de informaci√≥n para el c√°lculo del valor de salida de la neurona. La salida de la neurona, $0$ o $1$, est√° determinada con base en que la suma ponderada,\n",
        "\n",
        "$$\\displaystyle\\sum_{j}w_jx_j,$$\n",
        "\n",
        "<!-- $\\textbf{w}_{Layer}\\cdot\\textbf{x} =\n",
        "\\begin{bmatrix}\n",
        "w_{1, 1} & w_{1, 2} & \\cdots & w_{1, n}\\\\\n",
        "w_{2, 1} & w_{2, 2} & \\cdots & w_{2, n}\\\\\n",
        "\\vdots & \\vdots & \\ddots & \\vdots\\\\\n",
        "w_{m, 1} & w_{m, 2} & \\cdots & w_{m, n}\\\\\n",
        "\\end{bmatrix} \\cdot\n",
        "\\begin{bmatrix}\n",
        "x_1\\\\\n",
        "x_2\\\\\n",
        "\\vdots\\\\\n",
        "x_n\n",
        "\\end{bmatrix}$ -->\n",
        "\n",
        "(para $j \\in \\{1, 2, ..., n\\}$ ) sea menor o mayor que un **valor l√≠mite** que por ahora llamaremos **umbral**. (Aqu√≠ comenzamos con la formalizaci√≥n de lo que es un TLU y c√≥mo funciona.)\n",
        "\n",
        "Visto de otro modo, una neurona artificial puede interpretarse como un sistema que toma decisiones con base en la evidencia presentada."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q33kCpXyFgJ_"
      },
      "source": [
        "#### **Implementemos una TLU**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLBMuek3lBHd"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "# Primero creamos nuestra clase TLU\n",
        "class TLU():\n",
        "    def __init__(self, inputs, weights):\n",
        "        \"\"\"Class constructor.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        inputs : list\n",
        "            List of input values.\n",
        "        weights : list\n",
        "            List of weight values.\n",
        "        \"\"\"\n",
        "\n",
        "        self.inputs = None # TODO: np.array <- inputs\n",
        "        self.weights = None # TODO: np.array <- weights\n",
        "\n",
        "    def decide(self, treshold):\n",
        "        \"\"\"Function that operates inputs @ weights.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        treshold : int\n",
        "            Threshold value for decision.\n",
        "        \"\"\"\n",
        "\n",
        "        # TODO: Inner product of data\n",
        "        pass"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "En la siguiente celada, tome en cuenta que el valor de output ser√° 1 si la suma ponderada de los inputs es mayor o igual que el umbral, y 0 en caso contrario.\n",
        "\n",
        "Por ejemplo, si la velocidad es de 10 km/h, el ritmo card√≠aco es de 120 bpm y la respiraci√≥n es de 20 rpm, y los pesos asociados son 0.5, 0.3 y 0.2, y el umbral es de 0.7, entonces la salida del perceptron ser√° 1. Esto significa que el perceptron predice que la persona est√° haciendo ejercicio."
      ],
      "metadata": {
        "id": "7hinAONnfmc2"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t42O74IdmKIw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41c90499-7fea-48b3-b48f-9a7af0c2d1cd"
      },
      "source": [
        "21# Now, we need to set inputs and weights\n",
        "\n",
        "inputs, weights = [], []\n",
        "\n",
        "questions = [\n",
        "    \"¬∑ ¬øCu√°l es la velocidad? \",\n",
        "    \"¬∑ ¬øRitmo cardiaco? \",\n",
        "    \"¬∑ ¬øRespiraci√≥n? \"\n",
        "]\n",
        "\n",
        "for question in questions:\n",
        "    i = int(input(question))\n",
        "    w = float(input(\"¬∑ Y su peso asociado es... \"))\n",
        "    inputs.append(i)\n",
        "    weights.append(w)\n",
        "    print()\n",
        "\n",
        "\n",
        "treshold = float(input(\"¬∑ Y nuestro umbral/l√≠mite ser√°: \"))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "¬∑ ¬øCu√°l es la velocidad? 10\n",
            "¬∑ Y su peso asociado es... 0.5\n",
            "\n",
            "¬∑ ¬øRitmo cardiaco? 120\n",
            "¬∑ Y su peso asociado es... 0.3\n",
            "\n",
            "¬∑ ¬øRespiraci√≥n? 20\n",
            "¬∑ Y su peso asociado es... 0.2\n",
            "\n",
            "¬∑ Y nuestro umbral/l√≠mite ser√°: 0.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZHjy-k33oNFm"
      },
      "source": [
        "artificial_neuron = TLU(inputs, weights) # TODO Instantiate Perceptron\n",
        "artificial_neuron.decide(treshold) # TODO Apply decision function with threshold"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gUCCwUG6DgCX"
      },
      "source": [
        "### **Bias y funciones de activaci√≥n ‚Äì El perceptr√≥n**\n",
        "\n",
        "_Antes de continuar, introduciremos otro conceptos, el **bias** y la **funci√≥n de activaci√≥n**._\n",
        "\n",
        "La operaci√≥n matem√°tica que realiza la neurona para la decisi√≥n de umbralizaci√≥n se puede escribir como:\n",
        "\n",
        "$$ f(\\textbf{x}) =\n",
        "  \\begin{cases}\n",
        "    0 & \\text{si $\\displaystyle\\sum_{j}w_jx_j <$ umbral o treshold} \\\\\n",
        "    1 & \\text{si $\\displaystyle\\sum_{j}w_jx_j \\geq$ umbral o treshold} \\\\\n",
        "  \\end{cases},$$\n",
        "\n",
        "donde $j \\in \\{1, 2, ..., n\\}$, y as√≠, $\\textbf{x} = (x_1, x_2, ..., x_n)$.\n",
        "\n",
        "De lo anterior, podemos despejar el umbral y escribirlo como $b$, obteniendo:\n",
        "\n",
        "$$ f(\\textbf{x}) =\n",
        "  \\begin{cases}\n",
        "    0 & \\text{si $\\displaystyle\\sum_{j}w_jx_j + b < 0$} \\\\\n",
        "    1 & \\text{si $\\displaystyle\\sum_{j}w_jx_j + b > 0$} \\\\\n",
        "  \\end{cases},$$\n",
        "\n",
        "donde $\\textbf{x} = (x_1, x_2, ..., x_n)$ y $j \\in \\{1, 2, ..., n\\}$.\n",
        "\n",
        "Esto que escribimos como $b$, tambi√©n se le conoce como **bias**, y describe *qu√© tan susceptible la red es a __dispararse__*.\n",
        "\n",
        "Curiosamente, esta descripci√≥n matem√°tica encaja con una funci√≥n de salto o de escal√≥n (funci√≥n [_Heaviside_](https://es.wikipedia.org/wiki/Funci%C3%B3n_escal%C3%B3n_de_Heaviside)), que es una **funci√≥n de activaci√≥n**. Esto es, una funci√≥n que permite el paso de informaci√≥n de acuerdo a la entrada y los pesos, permitiendo el disparo del lo procesado hacia la salida. La funci√≥n de salto se ve como sigue:\n",
        "\n",
        "<center>\n",
        "    <img src=\"https://upload.wikimedia.org/wikipedia/commons/4/4a/Funci%C3%B3n_Cu_H.svg\" width=\"40%\" alt=\"Funci√≥n escal√≥n de Heaviside\">\n",
        "</center>\n",
        "\n",
        "Sin embargo, podemos hacer a una neurona a√∫n m√°s susceptible con respecto a los datos de la misma (entradas, pesos, bias) a√±adiendo una funci√≥n [sigmoide](https://es.wikipedia.org/wiki/Funci%C3%B3n_sigmoide). Esta fue una de las agregaciones de Rosenblatt al momento del desarrollo de su propuesta de perceptr√≥n. La funci√≥n sigmoide se ve como a continuaci√≥n:\n",
        "\n",
        "<center>\n",
        "    <img src=\"https://upload.wikimedia.org/wikipedia/commons/6/66/Funci%C3%B3n_sigmoide_01.svg\" width=\"40%\" alt=\"Funci√≥n sigmoide\">\n",
        "</center>\n",
        "\n",
        "Esta funci√≥n es suave, y por lo tanto tiene una diferente \"sensibililad\" a los cambios abruptos de valores. Tambi√©n, sus entradas en lugar de solo ser $1$'s o $0$'s, pueden ser valores en todos los n√∫meros reales. La funci√≥n sigmoide es descrita por la siguiente expresi√≥n matem√°tica:\n",
        "\n",
        "$$f(z) = \\dfrac{1}{1+e^{-z}}$$\n",
        "\n",
        "O escrito en t√©rminos de entradas, pesos y bias:\n",
        "\n",
        "$$f(z) = \\dfrac{1}{1+\\exp{\\left\\{-\\left(\\displaystyle\\sum_{j}w_jx_j +b\\right)\\right\\}}}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0G1MY4HQFsEd"
      },
      "source": [
        "#### **Volviendo al ejemplo**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qSn8VaEoDtHo"
      },
      "source": [
        "# Modificamos para a√±adir la funci√≥n de activaci√≥n\n",
        "class Perceptron():\n",
        "    def __init__(self, inputs, weights):\n",
        "        \"\"\"Class constructor.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        inputs : list\n",
        "            List of input values.\n",
        "        weights : list\n",
        "            List of weight values.\n",
        "        \"\"\"\n",
        "\n",
        "        self.inputs = None # TODO: np.array <- inputs\n",
        "        self.weights = None # TODO: np.array <- weights\n",
        "\n",
        "    def decide(self, bias):\n",
        "        \"\"\"Function that operates inputs @ weights.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        bias : int\n",
        "            The bias value for operation.\n",
        "        \"\"\"\n",
        "\n",
        "        # TODO: Inner product of data + bias\n",
        "        # TODO: Apply sigmoid function f(z) = 1 / (1 + e^(-z))\n",
        "        pass"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "En la siguiente celda considere que el valor de output ser√° 1 si la suma ponderada de los inputs m√°s el bias es mayor o igual que el umbral, y 0 en caso contrario.\n",
        "\n",
        "Por ejemplo, si el bias es de 0.5, y el resto de los valores son los mismos que en el ejemplo anterior, entonces la salida del perceptron ser√° 1\n",
        "\n",
        "Esto significa que el perceptron predice que la persona est√° haciendo ejercicio, incluso con un bias m√°s alto.\n",
        "\n",
        "Un valor m√°s alto para el bias har√° que el perceptron sea m√°s sensible a los inputs. Esto significa que el perceptron ser√° m√°s probable que prediga 1, incluso si la suma ponderada de los inputs es solo ligeramente mayor que el umbral.\n",
        "\n",
        "Un valor m√°s bajo para el bias har√° que el perceptron sea menos sensible a los inputs. Esto significa que el perceptron ser√° menos probable que prediga 1, incluso si la suma ponderada de los inputs es mucho mayor que el umbral."
      ],
      "metadata": {
        "id": "kD5-Q99Sg8ha"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ogPy6NpfERfJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd965c0a-66d7-45af-9ca5-856dcc43d76a"
      },
      "source": [
        "bias = float(input(\"¬∑ El nuevo bias ser√°: \"))\n",
        "perceptron = Perceptron(inputs, weights)\n",
        "perceptron.decide(bias)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "¬∑ El nuevo bias ser√°: 0.5\n"
          ]
        }
      ]
    }
  ]
}