{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8gGSGsR--45"
      },
      "source": [
        "# Preprocesamiento de textos (Normalización)\n",
        "\n",
        "* Antes de procesar los texto con cualquier algoritmo de aprendizaje automático (supervisado o no supervisado) es necesario realizar un preporcesamiento con el objetivo de limpiar, normalizar y estructurar el texto.\n",
        "\n",
        "* Para ello se propone el siguiente framework:\n",
        "  * Eliminación de Ruido\n",
        "  * Tokenización\n",
        "  * Normalización\n",
        "\n",
        "* Los pasos propuestos en este framework pueden abordarse en el orden que se quiera e incluso alguno de estas etapas no sería necesario realizarse en función de como tengamos los textos.\n",
        "\n",
        "* Definamos a continuación lo que hay que realizar en cada uno de estos pasos:\n",
        "\n",
        "1.- ***Eliminación de ruido***:\n",
        "\n",
        "   * Este paso tiene como objetivo eliminar todos aquellos símbolos o caracteres que no aportan nada en el significado de las frases (ojo no confundir con las stop-words), como por ejemplo etiquetas HTML (para el caso del scraping), parseos de XML, JSON, etc.\n",
        "    \n",
        "2.- ***Tokenización***:\n",
        "   * Este paso tiene como objetivo dividir las cadenas de texto del documento en piezas más pequeñas o tokens.\n",
        "   * Aunque la tokenización es el proceso de dividir grandes cadenas de texto en cadenas más pequeñas, se suele diferenciar la:\n",
        "       * ***Segmentation***: Tarea de dividir grandes cadenas de texto en piezas más pequeñas como oraciones o párrafos.\n",
        "       * ***Tokenization***: Tarea de dividir grandes cadenas de texto solo y exclusivamente en palabras.\n",
        "    \n",
        "3.- ***Normalización***:\n",
        "\n",
        "   * La normalización es una tarea que tiene como objetivo poner todo el texto en igualdad de condiciones:\n",
        "        * Convertir todo el texto en mayúscula o minúsculas\n",
        "        * Eliminar, puntos, comas, comillas, etc.\n",
        "        * Convertir los números a su equivalente a palabras\n",
        "        * Quitar las Stop-words\n",
        "        * etc.\n",
        "        \n",
        "<hr>\n",
        "\n",
        "## Ejemplo de Preprocesamiento de Texto.\n",
        "\n",
        "\n",
        "* Aunque no hay una norma o guía de como realizar una normalización de texto ya que esta depende del problema a resolver y de la naturaleza del texto, vamos a mostrar a continuación algunas operaciones más o menos comúnes para la tokenización y normalización de los textos.\n",
        "\n",
        "\n",
        "* Si bien este ejemplo esta hecho utilizando la librería de ***spaCy*** (ya que lo vamos a aplicar sobre un texto en Español) puede realizarse tambien con la librería de ***NLTK*** e incluso determinadas funcionalidades de tratamiento de strings lo podemos hacer con otras librerías.\n",
        "\n",
        "\n",
        "* En el siguiente ejemplo vamos a tokenizar y normalizar un texto:\n",
        "    1. Transformar un texto en tokens\n",
        "    2. Eliminar los tokens que son signos (puntuación, exclamación, etc.)\n",
        "    3. Eliminar las palabras que tienen menos de 'N' caracteres\n",
        "    4. Eliminar las palabras que son Stop Words\n",
        "    5. Pasar el texto a minúsculas\n",
        "    6. Lematización"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download es"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XLr9cS2OA7yw",
        "outputId": "41d91189-8723-4eb5-817d-5445a8633222"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-11-08 03:40:09.323389: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-11-08 03:40:09.323442: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-11-08 03:40:09.323470: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-11-08 03:40:10.209862: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[38;5;3m⚠ As of spaCy v3.0, shortcuts like 'es' are deprecated. Please use the\n",
            "full pipeline package name 'es_core_news_sm' instead.\u001b[0m\n",
            "Collecting es-core-news-sm==3.6.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/es_core_news_sm-3.6.0/es_core_news_sm-3.6.0-py3-none-any.whl (12.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.9/12.9 MB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.7.0,>=3.6.0 in /usr/local/lib/python3.10/dist-packages (from es-core-news-sm==3.6.0) (3.6.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (8.1.12)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (2.0.10)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (0.9.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (0.10.3)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (4.66.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (1.23.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (1.10.13)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (23.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (2023.7.22)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (0.1.3)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (8.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (2.1.3)\n",
            "Installing collected packages: es-core-news-sm\n",
            "Successfully installed es-core-news-sm-3.6.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('es_core_news_sm')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "wet-HKGv--47"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "nlp = spacy.load('es_core_news_sm')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "V4kIq1YA--48"
      },
      "outputs": [],
      "source": [
        "def get_tokens(text):\n",
        "    \"\"\"\n",
        "    Función que dado un texto devuelve una lista con las palabras del texto no vacias\n",
        "    \"\"\"\n",
        "    doc = nlp(text)\n",
        "    return [word.text.strip() for word in doc if len(word.text.strip()) > 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "QDp0rAmn--49"
      },
      "outputs": [],
      "source": [
        "def remove_punctuation(words):\n",
        "    \"\"\"\n",
        "    Función que dada una lista de palabras, elimina los signos de puntuación\n",
        "    \"\"\"\n",
        "    doc = spacy.tokens.doc.Doc(nlp.vocab, words=words)\n",
        "    return [word.text for word in doc if not word.is_punct]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "x20rpo2f--49"
      },
      "outputs": [],
      "source": [
        "def remove_short_words(words, num_chars):\n",
        "    \"\"\"\n",
        "    Función que dada una lista de palabras y un número mínimo de caracteres que tienen que tener\n",
        "    las palabras, elimina todas las palabras que tengan menos caracteres que los indicados\n",
        "    \"\"\"\n",
        "    return [word for word in words if len(word) > num_chars]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "PVcu-Qoj--49"
      },
      "outputs": [],
      "source": [
        "def remove_stop_words(words):\n",
        "    \"\"\"\n",
        "    Función que dada una lista de palabras, elimina las Stop Words\n",
        "    \"\"\"\n",
        "    doc = nlp(\" \".join(words))\n",
        "    return [word.text for word in doc if not word.is_stop]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "lOQuUvMg--49"
      },
      "outputs": [],
      "source": [
        "def to_lowercase(words):\n",
        "    \"\"\"\n",
        "    Función que dada una lista de palabras, las transforma a minúsculas\n",
        "    \"\"\"\n",
        "    return [word.lower() for word in words]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "DBBza3bc--49"
      },
      "outputs": [],
      "source": [
        "def lemmatizer(words):\n",
        "    \"\"\"\n",
        "    Función que dada una lista de palabras, devuelve esa lista con el lema de cada una de esas palabras\n",
        "    \"\"\"\n",
        "    doc = nlp(\" \".join(words))\n",
        "    return [word.lemma_ for word in doc]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "PNvHD6qa--49"
      },
      "outputs": [],
      "source": [
        "def normalize(text):\n",
        "    \"\"\"\n",
        "    Dado un texto, devuelve el texto tokenizado y normalizado\n",
        "    \"\"\"\n",
        "    words = get_tokens(text=text)\n",
        "    words = remove_punctuation(words=words)\n",
        "    words = remove_short_words(words=words, num_chars=3)\n",
        "    words = remove_stop_words(words)\n",
        "    words = to_lowercase(words)\n",
        "    words = lemmatizer(words)\n",
        "    return words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XHu3DG_6--4-"
      },
      "source": [
        "#### Pasamos a tokenizar y normalizar el siguiente texto usando la función de normalización realizada"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "cah4kIpg--4-",
        "outputId": "9938a21b-e6ba-482b-9139-a00458ed7c2f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['fernando', 'alonso', 'vuelto', 'sacar', 'petróleo', 'carrera', 'salir', 'acabar', 'premio', 'coronado', 'adelantar', 'pista', 'sebastiar', 'vettel', 'líder', 'mundial', 'querido', 'sacar', 'pecho', 'coche', 'tocado', 'problema', 'dirección', 'claro', 'desventaja', 'perder', 'recta', 'imposible', 'adelantar él', 'conseguir', 'pillar él', 'aber', 'pensar', 'curvo', 'poder', 'intentar', 'salir', 'contento', 'séptimos', 'sumar', 'punto', 'carrera', 'señalado']\n"
          ]
        }
      ],
      "source": [
        "raw = \"\"\"Fernando Alonso ha vuelto a sacar petróleo de la carrera, saliendo 13º y acabando 7º un\n",
        "         gran premio que ha coronado adelantando en pista a Sebastian Vettel, líder del Mundial.\n",
        "         Aunque no ha querido sacar pecho por ello: \"Su coche estaba tocado, tenía problemas de dirección,\n",
        "         estaban en clara desventaja e iba perdiendo cada vez más, vi que en la recta iba a ser imposible\n",
        "         adelantarle incluso con el DRS no conseguía pillarle así que como se abría mucho pensé que en la\n",
        "         primera curva que pudiera lo intentaba por dentro y a la primera salió bien y creo que hay que\n",
        "         estar contentos, séptimos otra vez, sumando puntos en las tres carreras\", ha señalado.\"\"\"\n",
        "print(normalize(raw))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6W5h4Pff--4_"
      },
      "source": [
        "#### En este ejemplo podemos ver como reducimos las palabras (tokens) del texto original, quedandonos con lo importante y normalizado\n",
        "#### Pasamos de 128 tokens del texto original a 44 tokens tras la normalización"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "AAXaFdNO--4_",
        "outputId": "fc2929f2-38ee-49cc-b8ed-b784811405da",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Número de tokens del texto original: 128\n",
            "Número de tokens distintos del texto original: 91\n",
            "Número de tokens tras la normalización: 43\n",
            "Número de tokens distintos tras la normalización: 40\n"
          ]
        }
      ],
      "source": [
        "print('Número de tokens del texto original: ' + str(len(get_tokens(raw))))\n",
        "print('Número de tokens distintos del texto original: ' + str(len(set(get_tokens(raw)))))\n",
        "print('Número de tokens tras la normalización: ' + str(len(normalize(raw))))\n",
        "print('Número de tokens distintos tras la normalización: ' + str(len(set(normalize(raw)))))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SaPV8n3N--5A"
      },
      "source": [
        "<hr>\n",
        "\n",
        "\n",
        "# Tratamiento de Strings\n",
        "\n",
        "\n",
        "## Codificación de Caracteres (Unicode)\n",
        "\n",
        "\n",
        "* Uno de los quebraderos de cabeza que se tiene a la hora de trabajar con python (sobre todo con python 2.X) es el tema de la ***codificación de los textos (Strings)***.\n",
        "\n",
        "\n",
        "* En un principio los ordenadores se diseñaron para utilizar el alfabeto ingles (que entre otras cosas no tiene ni acentos ni letras como la \"ñ\" para el Español) y por ese motivo se definió la codificación ***ASCII*** (***A***merican ***S***tandard ***C***ode for ***I***nformation ***I***nterchange) definido con 128 caracteres (7 bits para representar los 2<sup>7</sup> = 128 caracteres).\n",
        "\n",
        "\n",
        "* Dado que en el resto de lenguas en el mundo hay muchos más caracteres, se definió una nueva codificación de caracteres denominada como ***UNICODE*** que representa alrededor de 110.000 caracteres.\n",
        "\n",
        "\n",
        "* Por tanto para poder trabajar con Strings (codificados de diferente manera) se debería hacer lo siguiente:\n",
        "\n",
        "    1. ¿Cual es la codificación de mi fichero original?\n",
        "    2. **Decode**: Paso el string de mi fichero a Unicode (cambio de codificación)\n",
        "    3. Realizo las operaciones que sean necesarias sobre los strings codificados en **Unicode**\n",
        "    4. **Encode**: Escribo de **Unicode** a otra **codificación** el string con el que he trabajado\n",
        "\n",
        "\n",
        "<hr>\n",
        "\n",
        "\n",
        "## Operaciones con Strings\n",
        "\n",
        "\n",
        "* Muchas veces tenemos que realizar operaciones de transforación sobre palabras o textos. A continuación se muestran algunas de las funciones más útiles para trabajar con strings:\n",
        "\n",
        "|Nombre Función|Funcionalidad|\n",
        "|---|---|\n",
        "|[s.find(t)](#M1)|index of first instance of string t inside s (-1 if not found)|\n",
        "|[s.rfind(t)](#M2)|index of last instance of string t inside s (-1 if not found)|\n",
        "|[s.index(t)](#M3)|like s.find(t) except it raises ValueError if not found|\n",
        "|[s.rindex(t)](#M4)|like s.rfind(t) except it raises ValueError if not found|\n",
        "|[s.join(text)](#M5)|combine the words of the text into a string using s as the glue|\n",
        "|[s.split(t)](#M6)|split s into a list wherever a t is found (whitespace by default)|\n",
        "|[s.splitlines()](#M7)|split s into a list of strings, one per line|\n",
        "|[s.lower()](#M8)|a lowercased version of the string s|\n",
        "|[s.upper()](#M9)|an uppercased version of the string s|\n",
        "|[s.title()](#M10)|a titlecased version of the string s|\n",
        "|[s.strip()](#M11)|a copy of s without leading or trailing whitespace|\n",
        "|[s.replace(t, u)](#M12)|replace instances of t with u inside s|"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CnY5zMDz--5A"
      },
      "source": [
        "<hr>\n",
        "\n",
        "\n",
        "### <a name=\"M1\">s.find(t)</a>\n",
        "\n",
        "\n",
        "* Encuentra la posición (indice) del string que se pasa como parámetro empezando a contar desde la izquierda.\n",
        "\n",
        "\n",
        "* Si no encuentra el string, devuelve valor -1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "fi7n-Rt6--5A",
        "outputId": "e5cb8e81-3583-4edc-e6c3-713bc076ff98",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "s = 'Ricardo Moya'\n",
        "s.find('Moya')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Wu_Nl6za--5B",
        "outputId": "e46dcd7e-c7b2-495b-913b-07796d3afb80",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "s.find('a')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "lm3HG1vq--5B",
        "outputId": "b819552f-fcda-436e-b6ff-8c7629abf65a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-1"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "s.find('e')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EiDITEPo--5B"
      },
      "source": [
        "<hr>\n",
        "\n",
        "\n",
        "### <a name=\"M2\">s.rfind(t)</a>\n",
        "\n",
        "\n",
        "* Hace lo mismo que \"s.find(t)\" pero empezando a contar desde la derecha."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Mw9zeFL5--5B",
        "outputId": "99110efb-0573-4f80-a322-f9c1b127f4d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "s.rfind('a')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "7nYU2m6l--5B",
        "outputId": "0dba7471-4f49-456c-bf25-523acf1ee7aa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "s.rfind('Moya')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b72I5wg6--5B"
      },
      "source": [
        "<hr>\n",
        "\n",
        "\n",
        "### <a name=\"M3\">s.index(t)</a>\n",
        "\n",
        "\n",
        "* Hace lo mismo que \"s.find(t)\", con la única diferencia que devuelve un error (en vez de un -1) si no encuentra el string que se pasa como parámetro."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "KAkdpYC4--5B",
        "outputId": "42df5c15-a0f6-4cc7-d97c-7a7db50ff891",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "s.index('Moya')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "RyjOahvD--5C",
        "outputId": "14fa1b95-a8c0-4f4e-f76e-811065c52c6b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "s.index('a')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "shJN_8k9--5C",
        "outputId": "8c90a2ac-0982-4907-e434-f1ddcd19b507",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-8ac0fc017686>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'e'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Devuelve un error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m: substring not found"
          ]
        }
      ],
      "source": [
        "s.index('e') # Devuelve un error"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2LmNvMPf--5C"
      },
      "source": [
        "<hr>\n",
        "\n",
        "\n",
        "### <a name=\"M4\">s.rindex(t)\n",
        "\n",
        "\n",
        "* Hace lo mismo que \"s.index(t)\" pero empezando a contar desde la derecha."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "4TB_ZeG1--5C",
        "outputId": "057c958f-a3ac-44d6-c39e-f3ad77d5ea70",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "s.rindex('a')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "gTvD11vv--5C",
        "outputId": "b22072e3-b6dd-43c0-cecc-2fe2bdccd745",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "s.rfind('Moya')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-N6tj1UG--5D"
      },
      "source": [
        "<hr>\n",
        "\n",
        "\n",
        "### <a name=\"M5\">separador.join(text)</a>\n",
        "\n",
        "\n",
        "* Une cada letra del string que se le pasa como parámetro con el separador."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "3ByCQlEc--5D",
        "outputId": "d39c68ef-29bf-4484-a401-39c9a1e66374",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'R-i-c-a-r-d-o- -M-o-y-a'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "'-'.join(s)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iuhA81el--5D"
      },
      "source": [
        "* Esta es una función muy utilizada para formar una cadena de texto con separador (por ejemplo un espacio en blanco) a partir de una lista o tupla:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "xPBwZpOu--5D",
        "outputId": "70695b69-f45d-4b89-dcbb-cd02c577b8ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Un radar multa a Mariano Rajoy por caminar demasiado rapido'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "lista = [\"Un\", \"radar\", \"multa\", \"a\", \"Mariano\", \"Rajoy\", \"por\", \"caminar\", \"demasiado\", \"rapido\"]\n",
        "' '.join(lista)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gchhk59---5D"
      },
      "source": [
        "<hr>\n",
        "\n",
        "\n",
        "### <a name=\"M6\">s.split(t)</a>\n",
        "\n",
        "\n",
        "* Divide el String \"***s***\" en una lista siempre que encuentre un separador \"***t***\".\n",
        "\n",
        "\n",
        "* Por defecto el separador es el espacio en blanco."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "63-P-asu--5D",
        "outputId": "b4405e24-7a2f-4b19-aa8f-b42490f074b7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Un',\n",
              " 'radar',\n",
              " 'multa',\n",
              " 'a',\n",
              " 'Mariano',\n",
              " 'Rajoy',\n",
              " 'por',\n",
              " 'caminar',\n",
              " 'demasiado',\n",
              " 'rapido']"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "texto = \"Un radar multa a Mariano Rajoy por caminar demasiado rapido\"\n",
        "texto.split(' ')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W2dnOB6H--5D"
      },
      "source": [
        "<hr>\n",
        "\n",
        "\n",
        "### <a name=\"M7\">s.splitlines()</a>\n",
        "\n",
        "\n",
        "* Divide un String \"***s***\" en una lista siempre que encuentre un salto de linea (\\n)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "Z3y_KU0J--5E",
        "outputId": "69995541-3e72-4e1c-c82f-774a21335318",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[' linea 1', 'linea 2', 'linea 3']"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "texto = \"\"\" linea 1\\nlinea 2\n",
        "linea 3\n",
        "\"\"\"\n",
        "\n",
        "texto.splitlines()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jULjCD4H--5E"
      },
      "source": [
        "<hr>\n",
        "\n",
        "\n",
        "### <a name=\"M8\">s.lower()</a>\n",
        "\n",
        "\n",
        "* Transforma un String \"***s***\" a minúsculas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "UFu8BN49--5E",
        "outputId": "b6a97f63-b341-49a8-ec9c-3e67c323da36",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'minusculas'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "s = \"MiNuSCuLaS\"\n",
        "s.lower()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K7pgA7TM--5E"
      },
      "source": [
        "<hr>\n",
        "\n",
        "\n",
        "### <a name=\"M9\">s.upper()</a>\n",
        "\n",
        "\n",
        "* Transforma un String \"***s***\" a mayúsculas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "CBr_J6za--5J",
        "outputId": "2c583e28-e6fb-4ff5-ab20-8d0692e2509a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'MAYUSCULAS'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "s = \"mAyUscUlAs\"\n",
        "s.upper()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lerua3ck--5J"
      },
      "source": [
        "<hr>\n",
        "\n",
        "\n",
        "### <a name=\"M10\">s.title()</a>\n",
        "\n",
        "\n",
        "* Transforma el String \"***s***\" en formato título; es decir, pone la primera letra de cada palabra de String en mayúsculas y el resto en minúsculas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "1sj_dYN8--5J",
        "outputId": "0b3b8b00-808e-4c67-eb0a-100860d93d0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Ricardo Moya'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "s = \"rIcArdO mOyA\"\n",
        "s.title()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRPpv8VG--5J"
      },
      "source": [
        "<hr>\n",
        "\n",
        "\n",
        "### <a name=\"M11\">s.strip()</a>\n",
        "\n",
        "\n",
        "* Elimina los espacios en blanco y caracteres espaciales que hay tanto a la decrecha como a la izquierda del String \"***s***\".\n",
        "\n",
        "\n",
        "* Existen también las variantes de:\n",
        "    - s.rstrip(): Elimina los espacios en blanco y caracteres espaciales que hay a la derecha del string.\n",
        "    - s.lstrip(): Elimina los espacios en blanco y caracteres espaciales que hay a la izquierda del string."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "vdH_94zj--5J",
        "outputId": "5dd06c37-4f39-487b-88db-9a37cb6ec247",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Ricardo Moya'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "s = \"   \\tRicardo Moya  \\t  \"\n",
        "s.strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "aR8NbVwb--5K",
        "outputId": "001460dd-f4bb-4d46-bd9a-89a44f9e9a2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'   \\tRicardo Moya'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "s.rstrip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "h02kl8li--5K",
        "outputId": "bfd65db6-2e91-4ab7-f566-945b85508d01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Ricardo Moya  \\t  '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "s.lstrip()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PAwvlWng--5K"
      },
      "source": [
        "<hr>\n",
        "\n",
        "\n",
        "### <a name=\"M12\">s.replace(t, u)</a>\n",
        "\n",
        "\n",
        "* Dado un String \"***s***\" sustituye cada aparición \"***t***\" por \"***u***\", pasandose \"***t***\" y \"***u***\" como parámetro."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "foiPixPq--5K",
        "outputId": "066f99a1-f574-4a0b-f747-5ac2da54a6e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Un radar multa a un tio por caminar demasiado rapido'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "s = \"Un radar multa a Mariano Rajoy por caminar demasiado rapido\"\n",
        "s.replace(\"Mariano Rajoy\", \"un tio\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.11"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}